\section{Bandit Approach - Introduction} 

There is a clear trend in research and recent commercial products towards
robotic prostheses that promise to ameliorate the gait deficiencies imposed by
prevailing mechanically-passive devices. With the robotization of prostheses,
clinicians can now tune a large number of control parameters in order to
maximize the performance of these devices for each user.

Given the variability in human gait patterns, it is important to tailor these
gait policies for specific users.  Recently, \citet{zhang2017human} demonstrated
this by optimizing an ankle exoskeleton's torque trajectory for specific users.
The authors found that optimized torque trajectories could reduce metabolic
energy consumption beyond that provided by a generic assistance strategy.

Others have investigated optimization methods for prostheses specifically. For
example, \citet{huang2016cyber} propose a cyber expert system that uses
pre-defined rules to modify impedance control parameters in order to improve the
trajectory-tracking performance of a powered knee prosthesis. This approach was
later improved by using adaptive reinforcement learning to circumvent
predefining the tuning rules \citep{wen2016adaptive}. 

A drawback of these previously proposed methods are their reliance on numeric
optimization criteria, such as metabolic energy or trajectory tracking
performance. It is unclear if optimizing prostheses to follow a specific
trajectory will result in a positive outcome given the asymmetries in actuation,
kinematics, and inertia induced by an amputation and wearing a prosthesis.
Moreover, myopic optimization of a single aspect of gait may neglect other
characteristics that are often subjective such as comfort and confidence.
Therefore, in this work, we utilize subjective preferences between pairs of
policy parameters in order to achieve a more holistic approach to prosthesis
optimization.

A second difficulty for existing methods is tackling the high dimensional,
constrained optimization problem imposed by multi-joint assistive devices such
as transfemoral prostheses. Previously published impedance control strategies
for transfemoral prostheses have roughly 30 tunable parameters for a given gait
condition, such as walking at a specific speed. \citet{sup2011upslope} show that
these parameters also vary with alternative conditions such as incline.
Therefore, these kinds of parameterized policies could require on the order of
100 parameters to deal with a range of situations. Previous work has attempted
to reduce the number of parameters via heuristic rules that tie impedance
parameters to other states of the prosthesis such as joint angles
\citep{simon2014configuring}.  However, it is not obvious how to translate these
heuristics to other control strategies, such as neuromuscular control
\citep{thatte2016toward}, which models muscles and neural reflexes, or
phase-based control \citep{quintero2016preliminary}, which follows knee and
ankle trajectories parameterized as functions of hip angle and hip angle
integral.

To deal with high-dimensional parameter selection for prostheses, many have
turned to offline optimization of control parameters \citet{markowitz2011speed}
use data from a height-and weight-matched intact subject to obtain
speed-adaptive neuromuscular control parameters for a transtibial amputee's
prosthesis and \citet{aghasadeghi2013learning} use an invariant gait
representation to model an amputee's gait and find the appropriate impedance
control parameters. In these approaches however, it is unclear how well the
resultant parameters suit the subject when executed on actual hardware.

In this paper, we tackle these issues by framing prosthesis optimization as a
dueling bandits problem \citep{yue2012k}. The resulting approach utilizes the
subject's preferences to include subjective user feedback in the tuning process.
The method deals with high dimensional optimization problems by incorporating
domain knowledge in the form of an offline optimization step. We show that this
method produces a library of parameters from which different users prefer
different options and for which preferred controllers tend to follow human gait
trends. Moreover, we explore further utilizing the offline optimization to help
the controllers generalize to speeds that were not included during the online
optimization process.
